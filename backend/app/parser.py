# backend/app/parser.py
import re
from typing import Dict, Optional

import pdfplumber
import re

# ---- Header mapping (expanded for common US/KR financial labels) ----
HEADER_MAP: Dict[str, list[str]] = {
    "revenue": [r"net sales", r"revenue", r"sales", r"매출(?:액)?"],
    "op_income": [r"operating income", r"operating profit", r"영업이익"],
    "net_income": [r"net income", r"net earnings", r"당기순이익|순이익"],
    "total_assets": [r"total assets", r"자산총계"],
    "total_liabilities": [r"total liabilities", r"부채총계"],
    "operating_cf": [
        r"net cash.*operating",
        r"cash provided by operating activities",
        r"cash generated by operating activities",
        r"영업활동현금흐름",
    ],
    "inventory": [r"inventor(?:y|ies)", r"재고자산"],
}

# ---- Utilities ----
def _first_number_token(s: str) -> Optional[str]:
    """
    Safely extract the first numeric token from a messy string.
    Handles: $, commas, decimals, parentheses for negatives, and unit words.
    Returns None if no numeric token is found.
    """
    if not s:
        return None
    s = s.replace("\n", " ").replace("\r", " ").strip()
    # Match examples:
    # "$ 97,960", "(1,234)", "-12,345", "12,345 million", "1.2 billion", "123 억"
    m = re.search(
        r"""[\(\$]?\s*            # optional '(' or '$'
            -?\d[\d,\.]*          # number with optional commas/decimals
            \s*(?:million|billion|억)? # optional unit
            \)?                   # optional ')'
        """,
        s,
        flags=re.IGNORECASE | re.VERBOSE,
    )
    if not m:
        return None
    return m.group(0).strip()


def _normalize_number(s: str) -> float:
    """
    Normalize a numeric token string into a float (in plain units).
    Supports parentheses for negatives and units: million/billion/억.
    Removes currency symbols and commas.
    """
    if not s:
        return 0.0

    s = s.strip()
    # Remove common currency markers
    s = s.replace("$", "").replace("USD", "").replace("US$", "").strip()
    # Handle negative in parentheses
    neg = s.startswith("(") and s.endswith(")")
    s = s.strip("()").strip()

    # Identify and strip unit words
    scale = 1.0
    low = s.lower()
    if "billion" in low:
        # keep only numeric/./-/,
        core = re.sub(r"[^0-9\.\-]", "", low.replace("billion", ""))
        s = core
        scale = 1e9
    elif "million" in low:
        core = re.sub(r"[^0-9\.\-]", "", low.replace("million", ""))
        s = core
        scale = 1e6
    elif s.endswith("억"):
        s = s[:-1]
        scale = 1e8

    # Remove commas and spaces
    s = s.replace(",", "").replace(" ", "")
    val = float(s) if s else 0.0
    val *= scale
    return -val if neg else val


def _line_matches_any(header: str, patterns: list[str]) -> bool:
    h = header.lower()
    return any(re.search(pat, h, flags=re.IGNORECASE) for pat in patterns)


def parse_pdf_to_kpi(path: str) -> Dict[str, float]:
    """
    Parse a financial report PDF and extract key KPIs using a robust line scan.
    Strategy:
      1) Extract text from first few pages (fast, robust to most PDFs).
      2) For each header category (HEADER_MAP), find a line containing the header
         and then extract the FIRST numeric token that appears on that line.
      3) If token is found, normalize to float.
      4) Compute derived metrics like debt_ratio if possible.
    NOTE:
      - This is an MVP parser; accuracy can be improved with table parsing
        (camelot/tabula) and company-specific dictionaries.
    """
    text = ""
    with pdfplumber.open(path) as pdf:
        # Read first N pages to keep it fast while covering summary tables
        N = min(len(pdf.pages), 8)
        for i in range(N):
            page_text = pdf.pages[i].extract_text() or ""
            text += page_text + "\n"

    lines = [ln.strip() for ln in text.splitlines() if ln and ln.strip()]
    result: Dict[str, float] = {}

    for key, patterns in HEADER_MAP.items():
        if key in result:
            continue
        # Search each line for a header match, then find a numeric token
        for ln in lines:
            if not _line_matches_any(ln, patterns):
                continue
            # Allow $, parentheses, letters for unit words when cleaning
            cleaned = re.sub(r"[^0-9,().\-\sa-zA-Z$]", " ", ln)
            token = safe_first_token(cleaned)
            if token is None:
                # Could not find a number in this line; continue scanning next line
                continue
            try:
                result[key] = _normalize_number(token)
                break
            except Exception:
                # If normalization fails, try next occurrence
                continue

    # Derived KPI: debt ratio
    if result.get("total_assets") and result.get("total_liabilities"):
        assets = result["total_assets"]
        liab = result["total_liabilities"]
        if assets:  # avoid division by zero
            result["debt_ratio"] = (liab / assets) * 100.0

    return result


def safe_first_token(num_str: str) -> Optional[str]:
    """Robustly extract a first numeric token from a string.

    Strategy:
      1) Try the primary regex-based extractor `_first_number_token` on the whole string.
      2) If not found, split the cleaned line by common delimiters (tabs, pipes) and
         try `_first_number_token` on each chunk.
      3) As a last resort, return the first whitespace-separated token that contains a digit.

    Returns None if no plausible token found.
    """
    if not num_str:
        return None

    # 1) Try the regex-based extractor directly
    t = _first_number_token(num_str)
    if t:
        return t

    # 2) Clean and split into chunks then try each chunk
    cleaned = re.sub(r"[^0-9,().\-\sa-zA-Z$]", " ", num_str)
    chunks = re.split(r"[\t|]", cleaned)
    for ch in chunks:
        ch = ch.strip()
        if not ch:
            continue
        t = _first_number_token(ch)
        if t:
            return t

    # 3) Fallback: take first whitespace token if it contains any digit
    parts = cleaned.strip().split()
    if parts:
        first = parts[0]
        if re.search(r"\d", first):
            return first

    return None